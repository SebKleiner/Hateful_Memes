{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from google.cloud import vision\n",
    "import os\n",
    "\n",
    "password_file = \"write here yours\" #Write here yours\n",
    "path = 'data/img/01235.png'\n",
    "\n",
    "def get_all(path, password_file):\n",
    "    \n",
    "    #Set up google vision\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=password_file\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    \n",
    "    #Read image\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "            content = image_file.read()\n",
    "    image = vision.types.Image(content=content)\n",
    "    \n",
    "    #Text detection\n",
    "    response = client.text_detection(image=image)  \n",
    "    texts = response.text_annotations\n",
    "    ret_text = [text.description for text in texts]\n",
    "    print(ret_text)\n",
    "    \n",
    "    #Label detection\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    ret_label = [label.description for label in labels]\n",
    "    print(ret_label)\n",
    "    \n",
    "    #Object detection \n",
    "    objects = client.object_localization(\n",
    "            image=image).localized_object_annotations\n",
    "    ret_object = [(object_.name, object_.score) for object_ in objects]\n",
    "    print(ret_object)\n",
    "    \n",
    "    return {'path': path, 'text': ret_text, 'labels': ret_label, 'objects': ret_object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "nltk.download('wordnet')\n",
    "from functools import partial\n",
    "\n",
    "SLANG_PATH='slang.txt'\n",
    "\n",
    "def preprocess(dicti):\n",
    "    \n",
    "    #Elongated function\n",
    "    def replaceElongated(word):\n",
    "    \"\"\" Replaces an elongated word with its basic form, unless the word exists in the lexicon \"\"\"\n",
    "    repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "    repl = r'\\1\\2\\3'\n",
    "    if wordnet.synsets(word):\n",
    "        return word\n",
    "    repl_word = repeat_regexp.sub(repl, word)\n",
    "    if repl_word != word:      \n",
    "        return replaceElongated(repl_word)\n",
    "    else:       \n",
    "        return repl_word\n",
    "    \n",
    "    #slang function\n",
    "    with open(SLANG_PATH) as file:\n",
    "        slang_map = dict(map(str.strip, line.partition('\\t')[::2])\n",
    "        for line in file if line.strip())\n",
    "\n",
    "    slang_words = sorted(slang_map, key=len, reverse=True)\n",
    "    regex = re.compile(r\"\\b({})\\b\".format(\"|\".join(map(re.escape, slang_words))))\n",
    "    replaceSlang = partial(regex.sub, lambda m: slang_map[m.group(1)])\n",
    "    \n",
    "    #Preprocess text\n",
    "    dicti['text'] = dicti['text'][0].replace('\\n', ' ')\n",
    "    dicti['text'] = replaceSlang(replaceElongated(dicti['text']))\n",
    "    #Preprocess objects\n",
    "    dicti['objects'] = set([el[0] for el in dicti['objects']])\n",
    "    #Preprocess labels\n",
    "    for label in ['Photo caption', 'Photography', 'Font', 'Text', 'Internet meme']:\n",
    "        if label in dicti['labels']:\n",
    "            dicti['labels'].remove(label)\n",
    "    return dicti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example of preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='48260.png'\n",
    "ret_text= ['woohooo pedal faster patrick,\\nthe owners are coming\\nasf',\n",
    "  'pedal',\n",
    "  'faster',\n",
    "  'patrick,',\n",
    "  'the',\n",
    "  'owners',\n",
    "  'are',\n",
    "  'coming']\n",
    "ret_label= ['Vehicle',\n",
    "  'Photo caption',\n",
    "  'Bicycle wheel',\n",
    "  'Bicycle',\n",
    "  'Bicycle tire',\n",
    "  'Cool',\n",
    "  'Font',\n",
    "  'Photography',\n",
    "  'Adaptation',\n",
    "  'Bicycle frame']\n",
    "ret_object = [('Bicycle wheel', 0.8897398114204407),\n",
    "  ('Person', 0.8209506273269653),\n",
    "  ('Bicycle wheel', 0.7898780107498169),\n",
    "  ('Jeans', 0.7539083957672119),\n",
    "  ('Bicycle wheel', 0.689781129360199),\n",
    "  ('Outerwear', 0.6768908500671387),\n",
    "  ('Bicycle', 0.6365995407104492),\n",
    "  ('Glasses', 0.6281065940856934),\n",
    "  ('Pants', 0.6200207471847534),\n",
    "  ('Hat', 0.5796813368797302)]\n",
    "dicti = {'path': path, 'text': ret_text, 'labels': ret_label, 'objects': ret_object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(dicti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
